# Agente IA para InstalaÃ§Ãµes ElÃ©tricas

Um agente de inteligÃªncia artificial projetado para auxiliar profissionais e pessoas leigas da Ã¡rea de construÃ§Ã£o civil, especialmente no segmento elÃ©trico, a tomar decisÃµes seguras e eficientes com base nas melhores prÃ¡ticas, normas tÃ©cnicas e cÃ¡lculos especializados.

---

## ğŸ§  Objetivo

O objetivo deste projeto Ã© oferecer uma API inteligente capaz de:

- Responder dÃºvidas sobre instalaÃ§Ãµes elÃ©tricas residenciais e comerciais.
- Realizar cÃ¡lculos elÃ©tricos (bitolas, disjuntores, potÃªncia, etc.).
- Buscar informaÃ§Ãµes tÃ©cnicas em normas e documentos especÃ­ficos (ex: NBR 5410).
- Auxiliar na tomada de decisÃ£o com explicaÃ§Ãµes baseadas em boas prÃ¡ticas.

A aplicaÃ§Ã£o estÃ¡ sendo construÃ­da com foco em modularidade e escalabilidade, utilizando IA generativa (LLMs) local atravÃ©s do Ollama.

---

## âš™ï¸ Tecnologias Utilizadas

- **FastAPI** â€“ API rÃ¡pida e moderna em Python
- **Ollama** â€“ LLM local para processamento de linguagem natural
- **Pydantic** â€“ ValidaÃ§Ã£o de dados e configuraÃ§Ãµes
- **Python 3.11+**
- **Requests** â€“ Cliente HTTP para comunicaÃ§Ã£o com Ollama

---

## ğŸ–¥ï¸ Como Rodar o Projeto Localmente

### 1. PrÃ©-requisitos

- Python 3.11 ou superior
- Ollama instalado e rodando localmente ([InstruÃ§Ãµes de instalaÃ§Ã£o do Ollama](https://ollama.ai/))
- Git

### 2. Clone o repositÃ³rio

```bash
git clone https://github.com/fsantosfp/effies-app-ia-electrical.git
cd effies-app-ia-electrical
```

### 3. Crie e ative um ambiente virtual
```bash
python -m venv venv

# Windows (Git Bash)
source venv/Scripts/activate

# Linux/macOS
source venv/bin/activate
```

### 4. Instale as dependÃªncias
```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### 5. Inicie o Ollama
Certifique-se de que o Ollama estÃ¡ rodando localmente na porta padrÃ£o (11434)

### 6. Execute a API
```bash
uvicorn main:app --reload
```

## ğŸš€ Usando a API

A API possui um endpoint principal para interaÃ§Ã£o com o agente:

### POST /ask
Envie perguntas para o agente atravÃ©s deste endpoint:

```json
{
  "agent": "assistant",
  "message": "Sua pergunta sobre instalaÃ§Ãµes elÃ©tricas aqui"
}
```

Exemplo de uso:
```bash
curl -X POST "http://localhost:8000/ask" \
     -H "Content-Type: application/json" \
     -d '{"agent": "assistant", "message": "Quantas tomadas posso colocar em um circuito de 2,5mm?"}'
```

## ğŸ“ Estrutura do Projeto
```
agente-eletrica/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ agent_selector.py    # SeleÃ§Ã£o de agentes especializados
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ agent.py            # LÃ³gica principal do agente
â”‚   â””â”€â”€ services/
â”‚       â””â”€â”€ ollama_client.py    # Cliente para comunicaÃ§Ã£o com Ollama
â”‚
â”œâ”€â”€ main.py                     # Ponto de entrada da API
â”œâ”€â”€ requirements.txt            # DependÃªncias do projeto
â””â”€â”€ README.md
```

## ğŸ“Œ Roadmap
- [x] CriaÃ§Ã£o do repositÃ³rio e documentaÃ§Ã£o inicial
- [x] Setup da API com FastAPI
- [x] IntegraÃ§Ã£o com Ollama
- [x] Sistema de seleÃ§Ã£o de agentes
- [ ] MÃ³dulo de cÃ¡lculos elÃ©tricos
- [ ] Base de conhecimento tÃ©cnico expandida
- [ ] Interface Web ou Mobile (futura)

## ğŸ“„ LicenÃ§a
Este projeto estÃ¡ sob a licenÃ§a MIT - veja o arquivo LICENSE para mais detalhes.

## ğŸ¤ Contribuindo
Se vocÃª deseja contribuir com melhorias ou novos mÃ³dulos, fique Ã  vontade para abrir uma issue ou enviar um pull request.

## ğŸ› Problemas Conhecidos
- Certifique-se de que o Ollama estÃ¡ rodando localmente antes de iniciar a API
- O modelo padrÃ£o usado Ã© o gemma:7b, certifique-se de tÃª-lo baixado no Ollama